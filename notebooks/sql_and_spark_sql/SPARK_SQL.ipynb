{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dd19d8c-49fa-401d-bf89-6447205d5666",
   "metadata": {},
   "source": [
    "* ```SparkSession:``` Ponto de entrada para usar o PySpark, responsável por criar e gerenciar a execução do Spark.\n",
    "* ```col:``` Permite acessar colunas do DataFrame Spark para transformações ou cálculos.\n",
    "* ```Funções de agregação (sum, avg):``` Realizam operações como soma e média sobre colunas.\n",
    "* ```Funções de janela (row_number, rank):``` Calculam valores relacionados a partições de dados, como numeração de linhas e rankings.\n",
    "* ```Window:``` Define especificações de janelas para operações de janela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7743a592-fbe9-4f79-9f38-d9b7d2713ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, avg, row_number, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = r\"C:\\Users\\cezar\\anaconda3\\envs\\deprep\\python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = r\"C:\\Users\\cezar\\anaconda3\\envs\\deprep\\python.exe\"\n",
    "\n",
    "# Criar uma sessão Spark\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Spark SQL Study\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6689717-b049-49e0-a6d6-6e5b41131b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cezar\\anaconda3\\envs\\deprep\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e32671b4-f74f-43ae-9143-64943c5bcc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executado no Spark (workers): C:\\Users\\cezar\\anaconda3\\envs\\deprep\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(\"Python executado no Spark (workers):\", spark.sparkContext.pythonExec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a84ad-2e33-47ea-8371-463fa8199605",
   "metadata": {},
   "source": [
    "* Cria um DataFrame Spark a partir do conjunto de dados fictício.\n",
    "* Define os nomes das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5186496b-c496-4a62-a52c-f242f576ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+------+------------+----------------+\n",
      "| id|  product|  category|region|sales_amount|transaction_date|\n",
      "+---+---------+----------+------+------------+----------------+\n",
      "|  1|Product A|Category 1| North|         100|      2023-01-01|\n",
      "|  2|Product B|Category 1| North|         200|      2023-01-02|\n",
      "|  3|Product C|Category 2| South|         300|      2023-01-03|\n",
      "|  4|Product D|Category 2| South|         400|      2023-01-04|\n",
      "|  5|Product E|Category 1| North|         150|      2023-01-05|\n",
      "+---+---------+----------+------+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dados fictícios\n",
    "data = [\n",
    "    (1, \"Product A\", \"Category 1\", \"North\", 100, \"2023-01-01\"),\n",
    "    (2, \"Product B\", \"Category 1\", \"North\", 200, \"2023-01-02\"),\n",
    "    (3, \"Product C\", \"Category 2\", \"South\", 300, \"2023-01-03\"),\n",
    "    (4, \"Product D\", \"Category 2\", \"South\", 400, \"2023-01-04\"),\n",
    "    (5, \"Product E\", \"Category 1\", \"North\", 150, \"2023-01-05\"),\n",
    "]\n",
    "\n",
    "# Criar um DataFrame Spark\n",
    "df = spark.createDataFrame(data, [\"id\", \"product\", \"category\", \"region\", \"sales_amount\", \"transaction_date\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfe1d2-f7c5-4fc9-917f-2a495b1bbe6b",
   "metadata": {},
   "source": [
    "* Registra o DataFrame como uma view temporária chamada ```sales```\n",
    "* Permite executar consultas SQL diretamente sobre os dados usando ```spark.sql```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80760efd-36bf-4f7e-8aa0-75e778c9c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma view temporária para SQL\n",
    "df.createOrReplaceTempView(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d567216a-d251-4336-8d37-a172a0737937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta Básica: Produtos na região 'North'\n",
      "+---------+------------+\n",
      "|  product|sales_amount|\n",
      "+---------+------------+\n",
      "|Product A|         100|\n",
      "|Product B|         200|\n",
      "|Product E|         150|\n",
      "+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Consulta Básica em Spark SQL\n",
    "print(\"Consulta Básica: Produtos na região 'North'\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    product,\n",
    "    sales_amount\n",
    "FROM\n",
    "    sales\n",
    "WHERE\n",
    "    region = 'North'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eff329f1-efb4-464c-b56a-a315df4a546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma de vendas por região\n",
      "+------+-----------+\n",
      "|region|total_sales|\n",
      "+------+-----------+\n",
      "| South|        700|\n",
      "| North|        450|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Soma de vendas por região (GROUP BY)\n",
    "print(\"Soma de vendas por região\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    region,\n",
    "    SUM(sales_amount) AS total_sales\n",
    "FROM\n",
    "    sales\n",
    "GROUP BY\n",
    "    region\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1dd29-5929-48f9-963b-c996064bfd17",
   "metadata": {},
   "source": [
    "* ```Window.partitionBy(\"region\")```: Cria partições por região (```North```, ```South```).\n",
    "* ```orderBy(\"transaction_date\")```: Ordena os dados por data dentro de cada partição.\n",
    "* ```sum(\"sales_amount\").over(windowSpec)```: Calcula a soma acumulada de vendas (```running_total```) dentro de cada partição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c1d6e3b-83fc-4563-ae5b-2f1e44c4a08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soma acumulada por região\n",
      "+------+---------+------------+-------------+\n",
      "|region|  product|sales_amount|running_total|\n",
      "+------+---------+------------+-------------+\n",
      "| North|Product A|         100|          100|\n",
      "| North|Product B|         200|          300|\n",
      "| North|Product E|         150|          450|\n",
      "| South|Product C|         300|          300|\n",
      "| South|Product D|         400|          700|\n",
      "+------+---------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Função de Janela: Soma acumulada por região\n",
    "print(\"Soma acumulada por região\")\n",
    "windowSpec = Window.partitionBy(\"region\").orderBy(\"transaction_date\")\n",
    "df = df.withColumn(\"running_total\", sum(\"sales_amount\").over(windowSpec))\n",
    "df.select(\"region\", \"product\", \"sales_amount\", \"running_total\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b81b4a-2674-4fcd-84c3-433f93e01a5f",
   "metadata": {},
   "source": [
    "* ```rank().over(windowSpec)```: Atribui um ranking às vendas de cada região, baseado no valor (```sales_amount```), respeitando a ordem especificada no ```windowSpec```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d44203ed-053f-4aed-bb4c-0baa0dd2e826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking de vendas por região\n",
      "+------+---------+------------+----------+\n",
      "|region|  product|sales_amount|sales_rank|\n",
      "+------+---------+------------+----------+\n",
      "| North|Product A|         100|         1|\n",
      "| North|Product B|         200|         2|\n",
      "| North|Product E|         150|         3|\n",
      "| South|Product C|         300|         1|\n",
      "| South|Product D|         400|         2|\n",
      "+------+---------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Ranqueamento de vendas por região\n",
    "print(\"Ranking de vendas por região\")\n",
    "df = df.withColumn(\"sales_rank\", rank().over(windowSpec))\n",
    "df.select(\"region\", \"product\", \"sales_amount\", \"sales_rank\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203167e-bc87-4767-a669-ff1c23d5fd1b",
   "metadata": {},
   "source": [
    "* ```sales_total```: Calcula a soma total de todas as vendas.\n",
    "* ```withColumn(\"sales_percentage\", ...)```: Adiciona uma nova coluna com o percentual de vendas de cada produto em relação ao total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d75d219-56c2-48fd-b3ab-7c5664663ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------+----------------+\n",
      "|region|  product|sales_amount|sales_percentage|\n",
      "+------+---------+------------+----------------+\n",
      "| North|Product A|         100|           8.70%|\n",
      "| North|Product B|         200|          17.39%|\n",
      "| South|Product C|         300|          26.09%|\n",
      "| South|Product D|         400|          34.78%|\n",
      "| North|Product E|         150|          13.04%|\n",
      "+------+---------+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Cálculo de Percentual de Vendas\n",
    "from pyspark.sql.functions import col, format_string\n",
    "\n",
    "# Calculando o total de vendas\n",
    "sales_total = df.groupBy().sum(\"sales_amount\").collect()[0][0]\n",
    "\n",
    "# Adicionando a coluna formatada como percentual\n",
    "df = df.withColumn(\"sales_percentage\", \n",
    "                   format_string(\"%.2f%%\", (col(\"sales_amount\") / sales_total) * 100))\n",
    "\n",
    "# Exibindo as colunas desejadas\n",
    "df.select(\"region\", \"product\", \"sales_amount\", \"sales_percentage\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c977da2b-5e0b-4cbd-a2b5-f2837397fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerrar a sessão Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deprep)",
   "language": "python",
   "name": "deprep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
